## Project Description

** DocTalk performs summarization and keyphrase extraction.
Doctalk downloads stanza_corenlp and nltk_data automatically , please make sure that there is internet access.


## The Directories 
 - EvalCraft           # The ROUGE evaluator that calls doctalk to process documents, calculating ROUGE score
 - EvalCraft/doctalk/  # Our graph-based keyphrase extraction and summarization model
 - EvalCraft/dataset/  # Contains sample documents from various datasets we used in the paper. 


## Datasets:
Under the directory EvalCraft/dataset/, there are several subdirectories that each contain sample files from a dataset. 
NOTE: In the interest of decreasing the document's size to enable easy upload, each dataset directory contains only about 5 documents from the dataset.

EvalCraft/dataset/:
  - Inspec  # Inspec dataset, used for keyphrase extraction
  - Krapivin_Full    # Full documents from the Krapivin dataset, used by us for both keyphrase extraction and summarization.
  - Krapivin_NoAbstract  # Abstract-removed documents from the Krapivin dataset, used by us for both keyphrase extraction and summarization.
  - NUS_Full   # Full documents from the NUS dataset, used by us for both keyphrase extraction and summarization.
  - NUS_NoAbstract  # Abstract-removed documents from the NUS dataset, used by us for both keyphrase extraction and summarization.
  - SemEval_Full    # Full documents from the SemEval dataset, used by us for both keyphrase extraction and summarization
  - SemEval_NoAbstract   # Abstract-removed documents from the SemEval dataset, used by us for both keyphrase extraction and summarization
  - PubMed    # PubMed dataset, for summarization
  - arXiv     # arXiv dataset, for summarization

each dataset directory (ex. EvalCraft/dataset/Inspec/) has the subdirectories:
  - abs   # Gold-standard summaries
  - docsutf8   # original article
  - keys    # Gold-standard keyphrases
  - temp_docs # json files generated by stanza_corenlp parser
  - out    # Directory containing Keyphrases and summaries generated by DocTalk
    - out/keys # Keyphrases generated by DocTalk
    - out/abs # Summaries generated by DocTalk

If you'd like to do full tests on datasets, you can put all articles from a dataset into docsutf8 and put the gold standard keyphrases and summaries into keys and abs respectively.  
The datasets our model was tested on are available at:

arXiv and PubMed: https://github.com/armancohan/long-summarization
Krapivin, SemEval, NUS, Inspec: https://github.com/snkim/AutomaticKeyphraseExtraction



## Run eval_sumkeys Python Files to Evaluate DocTalk's performance on Keyphrase Extraction and Summarization
   There are several files with names that start with eval_sumkeys-, each file corresponds to one type of dataset we tested our model on. By directly running one of the files, ROUGE scores will be calculated and outputted for that test.
   - eval_sumkeys-Inspec.py : Inspec dataset
   - eval_sumkeys-Krapivin_Full.py : Krapivin dataset with full documents
   - eval_sumkeys-Krapivin_NoAbstract.py : Krapivin dataset with abstract-removed documents
   - eval_sumkeys-NUS_Full.py : NUS dataset with full documents
   - eval_sumkeys-NUS_NoAbstract.py : NUS dataset with abstract-removed documents
   - eval_sumkeys-SemEval_Full.py : SemEval dataset with full documents
   - eval_sumkeys-SemEval_NoAbstract.py : SemEval dataset with abstract-removed documents
   - eval_sumkeys-PubMed.py : PubMed dataset
   - eval_sumkeys-arXiv.py : arXiv dataset

A sample output is:

      EXTRACTED KEYS AND ABSTRACTS
                      Precision,          Recall,           F-Measure
      KEYS ROUGE 1 : 0.29827969008116073 0.4364484126984127 0.34144388195074693
      ABS ROUGE 1 : 0.49158123673586773    0.5043105876111166    0.48753007181944447
      ABS ROUGE 2 : 0.2825046451122882    0.29587238206313704    0.28307249204689017
      ABS ROUGE l : 0.5404513073395705    0.5515895825486291    0.537938640371076
      ABS ROUGE w : 0.27062101520754644    0.1830950391544452    0.21442998206315905
      DONE
      SYSTEM : DOCTALK
      wk 10 sk 8
      with_full_text =  False
      max_docs =  0
      force =  1


Parameters:
    in eval_sumkeys-* files, such as eval_sumkeys-Krapivin_Full.py
      - # 2 = forces deletion of json in temp_docs, 1 = forces deletion of keys+abs in out, 0 = deletes nothing
        force=0
      - # number of keyphrases and summary sentences
        wk,sk=10,8  # wk for number of keyphrases, sk for number of summary sentences
      - # sets maximum number of documents to be processed, all documents will be processed if set to 0
        max_docs = 0







